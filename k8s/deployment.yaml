
model            Ready    control-plane,master   3d1h   v1.33.3+k3s1
model-fbbc9de4   Ready    <none>                 3d     v1.33.3+k3s1 os pods estão so na master

Entendo que você está com um cluster K3s onde os pods estão sendo executados apenas no nó master, mesmo tendo um worker node disponível. Isso é comum e geralmente acontece devido a taints no worker node ou nodeSelector/affinity nos pods.

Vamos diagnosticar e resolver:

1. Verificar Taints nos Nós
bash
# Ver detalhes do nó master
kubectl describe node model

# Ver detalhes do worker
kubectl describe node model-fbbc9de4
Procure pela seção "Taints" em cada nó. O master geralmente tem um taint que permite scheduling.

2. Verificar se o Worker tem Taints
Se o worker tiver taints, você pode removê-los:

bash
# Remover todos os taints do worker
kubectl taint nodes model-fbbc9de4 --all-

# Ou remover um taint específico (exemplo)
kubectl taint nodes model-fbbc9de4 key=value:NoSchedule-
3. Verificar Labels e Roles
bash
# Ver labels dos nós
kubectl get nodes --show-labels

# Adicionar role de worker se necessário
kubectl label node model-fbbc9de4 node-role.kubernetes.io/worker=worker
4. Verificar Pods e seus Requerimentos
bash
# Ver onde os pods estão rodando
kubectl get pods -A -o wide

# Verificar se algum pod tem nodeSelector ou affinity
kubectl get pods -A -o json | grep -A5 nodeSelector
5. Forçar Distribuição de Pods
Para distribuir melhor os pods entre os nós, você pode:

bash
# Adicionar taint ao master para evitar pods não críticos
kubectl taint nodes model node-role.kubernetes.io/control-plane=true:PreferNoSchedule

# Ou ser mais restritivo (cuidado, isso pode afetar pods do sistema)
kubectl taint nodes model node-role.kubernetes.io/control-plane=true:NoSchedule
6. Verificar Recursos Disponíveis
bash
# Ver recursos disponíveis em cada nó
kubectl top nodes

# Ver detalhes de capacidade
kubectl describe nodes | grep -A 5 "Allocated resources"
Solução Mais Comum
Na maioria dos casos com K3s, basta remover possíveis taints do worker:

bash
kubectl taint nodes model-fbbc9de4 --all-
E então fazer um rollout dos deployments para redistribuir:

bash
kubectl rollout restart deployment -n <namespace> <deployment-name>
Você pode compartilhar a saída do comando kubectl describe node model-fbbc9de4 para eu poder dar uma orientação mais específica?


➜ ~ kubectl describe node model Name: model Roles: control-plane,master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/instance-type=k3s beta.kubernetes.io/os=linux kubernetes.io/arch=

pasted

Analisando os outputs, vejo que:

Ambos os nós estão sem Taints (Taints: <none>)
Ambos estão Ready e com recursos disponíveis
O worker node (model-fbbc9de4) tem apenas 1 pod rodando (svclb-traefik)
O master tem 8 pods, incluindo os 3 pods do talk-ci-deployment
O problema está nos seus deployments que não estão distribuindo os pods. Vamos verificar e corrigir:

1. Primeiro, adicionar label de role ao worker (opcional, mas ajuda na visualização):
bash
kubectl label node model-fbbc9de4 node-role.kubernetes.io/worker=worker
2. Verificar o deployment do talk-ci:
bash
kubectl get deployment talk-ci-deployment -n argocd -o yaml | grep -A 10 nodeSelector
kubectl get deployment talk-ci-deployment -n argocd -o yaml | grep -A 10 affinity
3. Verificar se há PodAntiAffinity ou outras configurações:
bash
kubectl describe deployment talk-ci-deployment -n argocd
4. Para forçar a distribuição dos pods entre os nós, você pode:
Opção A: Adicionar PodAntiAffinity ao deployment (recomendado)
bash
kubectl edit deployment talk-ci-deployment -n argocd
Adicione na seção spec.template.spec:

yaml
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - talk-ci  # ajuste conforme o label do seu pod
              topologyKey: kubernetes.io/hostname
Opção B: Usar o Descheduler (se quiser redistribuição automática)
bash
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: descheduler-policy-configmap
  namespace: kube-system
data:
  policy.yaml: |
    apiVersion: "descheduler/v1alpha1"
    kind: "DeschedulerPolicy"
    strategies:
      "RemoveDuplicates":
        enabled: true
      "LowNodeUtilization":
        enabled: true
        params:
          nodeResourceUtilizationThresholds:
            thresholds:
              "cpu" : 20
              "memory": 20
              "pods": 20
            targetThresholds:
              "cpu" : 50
              "memory": 50
              "pods": 50
EOF
Opção C: Escalar down e up para redistribuir (mais simples e rápido)
bash
# Escalar para 0
kubectl scale deployment talk-ci-deployment -n argocd --replicas=0

# Esperar pods terminarem
kubectl wait --for=delete pod -l app=talk-ci -n argocd --timeout=60s

# Escalar de volta para 3
kubectl scale deployment talk-ci-deployment -n argocd --replicas=3

# Verificar distribuição
kubectl get pods -n argocd -o wide
5. Para garantir melhor distribuição futura, você pode configurar o scheduler:
bash
# Adicionar preferência para distribuir pods
kubectl patch deployment talk-ci-deployment -n argocd --type='json' -p='[
  {
    "op": "add",
    "path": "/spec/template/spec/topologySpreadConstraints",
    "value": [
      {
        "maxSkew": 1,
        "topologyKey": "kubernetes.io/hostname",
        "whenUnsatisfiable": "DoNotSchedule",
        "labelSelector": {
          "matchLabels": {
            "app": "talk-ci"
          }
        }
      }
    ]
  }
]'
Verificar o resultado:
bash
kubectl get pods -n argocd -o wide
Se mesmo assim os pods não forem para o worker, verifique:

bash
# Ver eventos do deployment
kubectl describe deployment talk-ci-deployment -n argocd

# Ver logs do scheduler
kubectl logs -n kube-system $(kubectl get pods -n kube-system -l component=kube-scheduler -o name)
Qual dessas opções você prefere tentar primeiro?

➜  ~ kubectl describe deployment talk-ci-deployment -n argocd
Name:                   talk-ci-deployment
Namespace:              argocd
CreationTimestamp:      Sat, 23 Aug 2025 17:56:57 +0000
Labels:                 app=talk-ci
Annotations:            argocd.argoproj.io/tracking-id: example:apps/Deployment:argocd/talk-ci-deployment
                        deployment.kubernetes.io/revision: 1
Selector:               app=talk-ci
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=talk-ci
  Containers:
   talk-ci:
    Image:         desdiogo/2talk-ci
    Port:          80/TCP
    Host Port:     0/TCP
    Environment:   <none>
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   talk-ci-depl

Perfeito! O deployment está sem nenhuma configuração de afinidade ou nodeSelector. Vamos redistribuir os pods entre os nós. Vou sugerir a abordagem mais simples e efetiva:

1. Adicionar label ao worker (para melhor visualização):
bash
kubectl label node model-fbbc9de4 node-role.kubernetes.io/worker=worker --overwrite
2. Adicionar TopologySpreadConstraints para distribuir os pods:
bash
kubectl patch deployment talk-ci-deployment -n argocd --type='json' -p='[
  {
    "op": "add",
    "path": "/spec/template/spec/topologySpreadConstraints",
    "value": [
      {
        "maxSkew": 1,
        "topologyKey": "kubernetes.io/hostname",
        "whenUnsatisfiable": "DoNotSchedule",
        "labelSelector": {
          "matchLabels": {
            "app": "talk-ci"
          }
        }
      }
    ]
  }
]'
3. Forçar a redistribuição dos pods:
bash
# Deletar os pods existentes para forçar o reschedule
kubectl delete pods -n argocd -l app=talk-ci
4. Verificar a nova distribuição:
bash
# Ver onde os pods foram criados
kubectl get pods -n argocd -o wide

# Verificar pods por nó
kubectl get pods -A --field-selector spec.nodeName=model
kubectl get pods -A --field-selector spec.nodeName=model-fbbc9de4
Alternativa: Se preferir usar Anti-Affinity (distribui melhor):
bash
kubectl edit deployment talk-ci-deployment -n argocd
Adicione isso na seção spec.template.spec (no mesmo nível de containers):

yaml
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: talk-ci
              topologyKey: kubernetes.io/hostname
Depois salve e os pods serão redistribuídos automaticamente.

Resultado Esperado:
Com maxSkew: 1 e 3 réplicas em 2 nós, você deve ter:

2 pods em um nó
1 pod no outro nó
Isso garante a melhor distribuição possível com número ímpar de réplicas.

Execute os comandos e me mostre o resultado do kubectl get pods -n argocd -o wide para confirmarmos que funcionou!

estou usando o argocd

Ah, entendi! Como você está usando ArgoCD, as mudanças diretas no cluster serão revertidas pelo ArgoCD. Você precisa atualizar o manifesto no seu repositório Git.

Opções para resolver com ArgoCD:
Opção 1: Atualizar o manifesto no Git (Recomendado)
Edite o arquivo do deployment no seu repositório Git e adicione o topologySpreadConstraints:

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: talk-ci-deployment
  namespace: argocd
  labels:
    app: talk-ci
spec:
  replicas: 3
  selector:
    matchLabels:
      app: talk-ci
  template:
    metadata:
      labels:
        app: talk-ci
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: talk-ci
      containers:
      - name: talk-ci
        image: desdiogo/2talk-ci
        ports:
        - containerPort: 80
Depois faça o commit e push. O ArgoCD vai sincronizar automaticamente (ou você pode forçar):

bash
# Forçar sync se necessário
argocd app sync <nome-da-app>
# ou pela UI do ArgoCD
Opção 2: Usar Kustomize com ArgoCD
Se você estiver usando Kustomize, pode criar um patch:

kustomization.yaml:

yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - deployment.yaml

patches:
  - target:
      kind: Deployment
      name: talk-ci-deployment
    patch: |-
      - op: add
        path: /spec/template/spec/topologySpreadConstraints
        value:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: DoNotSchedule
            labelSelector:
              matchLabels:
                app: talk-ci
Opção 3: Usar Helm com ArgoCD
Se estiver usando Helm, adicione no values.yaml:

yaml
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: talk-ci
E no template do deployment:

yaml
spec:
  template:
    spec:
      {{- with .Values.topologySpreadConstraints }}
      topologySpreadConstraints:
        {{- toYaml . | nindent 8 }}
      {{- end }}
Opção 4: Temporariamente desabilitar auto-sync (não recomendado para produção)
bash
# Desabilitar auto-sync temporariamente
argocd app set <nome-da-app> --sync-policy none

# Fazer as mudanças
kubectl patch deployment talk-ci-deployment -n argocd --type='json' -p='[...]'

# Depois atualizar o Git e reabilitar
argocd app set <nome-da-app> --sync-policy automated
Verificar a aplicação no ArgoCD:
bash
# Ver status da aplicação
argocd app get <nome-da-app>

# Ver diferenças
argocd app diff <nome-da-app>
Qual método você está usando para gerenciar os manifestos? (Git direto, Kustomize, Helm?) Assim posso te dar a solução mais específica.

git quando tem atualiação o app é atualizado

Perfeito! Então você precisa atualizar o arquivo YAML do deployment no seu repositório Git.

Passos para resolver:
1. Localize o arquivo do deployment no seu repositório Git
Deve ser algo como talk-ci-deployment.yaml ou estar dentro de uma pasta como manifests/, k8s/, ou similar.

2. Edite o arquivo e adicione o topologySpreadConstraints
O arquivo atualizado deve ficar assim:

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: talk-ci-deployment
  namespace: argocd
  labels:
    app: talk-ci
spec:
  replicas: 3
  selector:
    matchLabels:
      app: talk-ci
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
  template:
    metadata:
      labels:
        app: talk-ci
    spec:
      # ADICIONE ESTA SEÇÃO AQUI
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: talk-ci
      # FIM DA SEÇÃO ADICIONADA
      containers:
      - name: talk-ci
        image: desdiogo/2talk-ci
        ports:
        - containerPort: 80
3. Commit e push das mudanças
bash
git add .
git commit -m "Add topology spread constraints to distribute pods across nodes"
git push
4. ArgoCD vai detectar a mudança e sincronizar
Você pode verificar o status:

bash
# Se tiver ArgoCD CLI instalado
argocd app list
argocd app sync <nome-da-sua-app>  # para forçar sync imediato

# Ou verificar via kubectl
kubectl get applications -n argocd
5. Após o sync, verifique a distribuição
bash
# Ver onde os pods estão rodando
kubectl get pods -n argocd -o wide

# Deve mostrar algo assim:
# NAME                                  READY   STATUS    NODE
# talk-ci-deployment-xxxxx-xxxxx        1/1     Running   model
# talk-ci-deployment-xxxxx-xxxxx        1/1     Running   model-fbbc9de4
# talk-ci-deployment-xxxxx-xxxxx        1/1     Running   model
Alternativa com Anti-Affinity (se preferir)
Se preferir usar anti-affinity em vez de topologySpreadConstraints:

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: talk-ci-deployment
  namespace: argocd
  labels:
    app: talk-ci
spec:
  replicas: 3
  selector:
    matchLabels:
      app: talk-ci
  template:
    metadata:
      labels:
        app: talk-ci
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: talk-ci
              topologyKey: kubernetes.io/hostname
      containers:
      - name: talk-ci
        image: desdiogo/2talk-ci
        ports:
        - containerPort: 80
Importante:

O topologySpreadConstraints força uma distribuição mais equilibrada
O podAntiAffinity com preferred tenta distribuir mas não é obrigatório
Com 3 réplicas e 2 nós, você terá 2 pods em um nó e 1 no outro
Faça a alteração no Git e o ArgoCD cuidará do resto! Me avise se precisar de ajuda com algo mais específico.

topologySpreadConstraints o que isso faz, pois tenho outro klluster com microk8s que funcionou nornamlmente a distribuição de pods

Ótima pergunta! Vou explicar o que é topologySpreadConstraints e por que seu MicroK8s distribui automaticamente mas o K3s não.

O que é topologySpreadConstraints?
É uma configuração que força o Kubernetes a distribuir pods de forma equilibrada entre nós (ou zonas). Ele define regras de como os pods devem ser espalhados.

yaml
topologySpreadConstraints:
- maxSkew: 1                    # Diferença máxima de pods entre nós
  topologyKey: kubernetes.io/hostname  # Distribuir por hostname (nós)
  whenUnsatisfiable: DoNotSchedule     # O que fazer se não conseguir
  labelSelector:                       # Quais pods contar
    matchLabels:
      app: talk-ci
maxSkew: 1 = A diferença máxima entre nós pode ser 1 pod (ex: 2 pods em um nó, 1 no outro)
whenUnsatisfiable: DoNotSchedule = Se não conseguir respeitar o maxSkew, não agenda o pod
topologyKey = Por qual característica distribuir (hostname = por nó)
Por que MicroK8s distribui automaticamente e K3s não?
1. Configurações padrão do Scheduler
MicroK8s geralmente vem com plugins e configurações que incluem:

Balanceamento automático via scheduler plugins
Descheduler addon que redistribui pods periodicamente
K3s é mais "minimalista" e usa configurações básicas do scheduler.

2. Scheduler Scoring
O scheduler do Kubernetes usa um sistema de pontuação. No seu caso:

No MicroK8s:

Provavelmente tem plugins como NodeResourcesFit, PodTopologySpread com pesos maiores
Penaliza mais nós com muitos pods
No K3s:

Usa scoring padrão que pode preferir o primeiro nó disponível
Menos peso para distribuição equilibrada
3. Como verificar as configurações do scheduler:
bash
# Ver a config do scheduler no K3s
kubectl get configmap -n kube-system kube-scheduler -o yaml

# No MicroK8s
microk8s kubectl get configmap -n kube-system scheduler-config -o yaml
Por que seus pods foram todos para o master no K3s?
Sem topologySpreadConstraints ou anti-affinity, o scheduler usa apenas o scoring padrão:

Primeiro pod: Master tinha 0 pods do app, worker tinha 0 → escolheu master (talvez por ordem alfabética ou latência menor)
Segundo pod: Sem anti-affinity, não há penalidade por colocar no mesmo nó → master de novo
Terceiro pod: Idem → master de novo
Soluções além do topologySpreadConstraints:
1. Configurar o Scheduler do K3s (global para todos os pods):
yaml
# /var/lib/rancher/k3s/server/manifests/scheduler-config.yaml
apiVersion: kubescheduler.config.k8s.io/v1beta3
kind: KubeSchedulerConfiguration
profiles:
- schedulerName: default-scheduler
  plugins:
    score:
      enabled:
      - name: NodeResourcesFit
        weight: 100
      - name: PodTopologySpread
        weight: 200  # Aumenta peso para distribuição
2. Instalar Descheduler (redistribui pods periodicamente):
bash
kubectl apply -f https://github.com/kubernetes-sigs/descheduler/releases/download/v0.27.0/descheduler.yaml
3. Usar preferredDuringScheduling (mais suave que topologySpread):
yaml
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchLabels:
            app: talk-ci
        topologyKey: kubernetes.io/hostname
Resumo:
MicroK8s: Vem com configurações que favorecem distribuição automática
K3s: Mais básico, precisa de configuração explícita
topologySpreadConstraints: Força distribuição equilibrada
Sem configuração: Scheduler pode colocar todos no mesmo nó se não houver razão para não fazer
Recomendação: Use topologySpreadConstraints para garantir distribuição, independente da distribuição Kubernetes que você usar. É mais previsível e portável!

o sync no argocd demora quanto tempo

O sync do ArgoCD pode variar bastante, mas vou te dar os tempos típicos:

Tempos de Sync do ArgoCD
1. Auto-Sync (Polling Interval)
Por padrão, o ArgoCD verifica mudanças no Git a cada 3 minutos (180 segundos).

bash
# Verificar o intervalo atual
kubectl get cm argocd-cm -n argocd -o yaml | grep timeout.reconciliation

# Ver quando foi o último sync
argocd app get <nome-da-app> | grep "Sync Status"
2. Sync Manual (Imediato)
bash
# Forçar sync agora
argocd app sync <nome-da-app>

# Ou via kubectl
kubectl patch app <nome-da-app> -n argocd --type merge -p '{"operation":{"initiatedBy":{"username":"admin"},"sync":{}}}'
3. Com Webhook (Quase instantâneo)
Se configurar webhook do Git → ArgoCD: ~5-10 segundos

Como acelerar o sync:
Opção 1: Diminuir o intervalo de polling (não recomendado para muitas apps)
yaml
# argocd-cm ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-cm
  namespace: argocd
data:
  timeout.reconciliation: 60s  # Reduz para 1 minuto
Opção 2: Configurar Webhook (Recomendado)
No GitHub/GitLab/Bitbucket, configure webhook para:

https://<argocd-server>/api/webhook
Opção 3: Forçar Sync Imediato via CLI
bash
# Se tiver o ArgoCD CLI
argocd app sync <nome-da-app>

# Ou usar a UI web do ArgoCD
# Clicar no botão "SYNC" na aplicação
Opção 4: Via UI do ArgoCD
bash
# Acessar a UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Abrir https://localhost:8080
# Login e clicar em "SYNC" na sua aplicação
Verificar status do sync:
bash
# Ver status em tempo real
watch -n 2 "kubectl get pods -n argocd -l app=talk-ci"

# Ver eventos da aplicação
kubectl get events -n argocd --sort-by='.lastTimestamp'

# Ver logs do ArgoCD
kubectl logs -n argocd deployment/argocd-repo-server -f
Para sua situação agora:
Como você acabou de fazer o push, pode:

Esperar ~3 minutos (sync automático)
Forçar sync agora:
bash
# Via port-forward rápido
kubectl port-forward svc/argocd-server -n argocd 8080:443 &
argocd login localhost:8080 --username admin --password <sua-senha>
argocd app sync <nome-da-sua-app>
argocd app wait <nome-da-sua-app>
Verificar se já sincronizou:
bash
# Ver se os pods foram recriados
kubectl get pods -n argocd -o wide | grep talk-ci

# Ver o manifesto atual
kubectl get deployment talk-ci-deployment -n argocd -o yaml | grep -A5 topologySpread
Dica: Se não souber o nome da app no ArgoCD:

bash
kubectl get applications -n argocd
Geralmente em 3-5 minutos já deve ter sincronizado. Se configurou webhook, em segundos!

atualizei para 4 pods agora ficou 3 no node filho e 1 na master

Ótimo progresso! O topologySpreadConstraints está funcionando, mas podemos melhorar a distribuição. Com 4 pods e 2 nós, o ideal seria 2 em cada nó.

Por que ficou 3-1 em vez de 2-2?
O maxSkew: 1 permite diferença de até 1 pod entre nós. Quando o Kubernetes escalou de 3 para 4 pods:

Master tinha 1 pod
Worker tinha 2 pods (ou vice-versa)
O 4º pod foi para onde tinha menos, mas depois algum pod pode ter sido recriado
Soluções para balancear melhor (2-2):
Opção 1: Forçar redistribuição deletando pods gradualmente
bash
# Ver distribuição atual
kubectl get pods -n argocd -l app=talk-ci -o wide

# Deletar 1 pod do nó com 3 pods (substitua pelo nome real)
kubectl delete pod <nome-do-pod-no-worker> -онарgocd

# Aguardar o novo pod ser criado (deve ir para o master)
kubectl get pods -n argocd -l app=talk-ci -o wide --watch
Opção 2: Ajustar o topologySpreadConstraints (mais rígido)
Atualize no Git para forçar distribuição mais equilibrada:

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: talk-ci-deployment
  namespace: argocd
  labels:
    app: talk-ci
spec:
  replicas: 4
  selector:
    matchLabels:
      app: talk-ci
  template:
    metadata:
      labels:
        app: talk-ci
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: talk-ci
      # Adicione anti-affinity também para reforçar
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: talk-ci
              topologyKey: kubernetes.io/hostname
      containers:
      - name: talk-ci
        image: desdiogo/2talk-ci
        ports:
        - containerPort: 80
Opção 3: Recreate strategy (mais rápido para rebalancear)
bash
# Escalar para 0 e voltar para 4
kubectl scale deployment talk-ci-deployment -n argocd --replicas=0
kubectl scale deployment talk-ci-deployment -n argocd --replicas=4

# Ver nova distribuição
kubectl get pods -n argocd -l app=talk-ci -o wide
Opção 4: Usar Rollout restart (preserva disponibilidade)
bash
# Força recreation gradual dos pods
kubectl rollout restart deployment talk-ci-deployment -n argocd

# Acompanhar
kubectl rollout status deployment talk-ci-deployment -n argocd
kubectl get pods -n argocd -l app=talk-ci -o wide
Para o futuro - Garantir distribuição equilibrada:
Com número PAR de réplicas (4, 6, 8...):
yaml
topologySpreadConstraints:
- maxSkew: 1
  topologyKey: kubernetes.io/hostname
  whenUnsatisfiable: DoNotSchedule
Deve distribuir igualmente (2-2, 3-3, 4-4...)

Com número ÍMPAR de réplicas (3, 5, 7...):
Sempre terá diferença de 1 pod (2-1, 3-2, 4-3...)

Verificar a distribuição:
bash
# Contagem por nó
kubectl get pods -n argocd -l app=talk-ci -o wide | grep -c model-fbbc9de4
kubectl get pods -n argocd -l app=talk-ci -o wide | grep -c "model "

# Ou mais visual
kubectl get pods -n argocd -l app=talk-ci --output=custom-columns=NAME:.metadata.name,NODE:.spec.nodeName
Qual opção você prefere tentar? A mais simples é a Opção 3 (scale down/up) ou Opção 4 (rollout restart).

agora ficou ao contrario rodando a pção tres na master e 1 n no no

Haha, o Kubernetes está "brincando" com você! Isso acontece porque o scheduler está respeitando o maxSkew: 1, mas não está rebalanceando perfeitamente. Vamos resolver isso de forma definitiva!

Problema: O scheduler está permitindo 3-1 porque:
maxSkew: 1 permite diferença de 1 pod
3 - 1 = 2 (diferença maior que 1), mas pode acontecer durante o scheduling sequencial
Solução Definitiva: Forçar 2-2
Opção 1: Deletar pods específicos (mais preciso)
bash
# 1. Ver onde estão os pods agora
kubectl get pods -n argocd -l app=talk-ci -o wide --no-headers | awk '{print $1, $7}'

# 2. Deletar 1 pod da master (que tem 3)
kubectl delete pod <nome-de-1-pod-na-master> -n argocd

# 3. Esperar criar e verificar
sleep 5
kubectl get pods -n argocd -l app=talk-ci -o wide --no-headers | awk '{print $1, $7}'

# 4. Se ainda não balanceou, deletar outro pod da master
kubectl delete pod <nome-de-outro-pod-na-master> -n argocd
Opção 2: Script para forçar distribuição 2-2
bash
# Criar todos os 4 pods de uma vez com pausa entre eles
kubectl scale deployment talk-ci-deployment -n argocd --replicas=0

# Esperar todos terminarem
kubectl wait --for=delete pod -l app=talk-ci -n argocd --timeout=60s 2>/dev/null || true

# Escalar gradualmente
kubectl scale deployment talk-ci-deployment -n argocd --replicas=2
sleep 10
kubectl scale deployment talk-ci-deployment -n argocd --replicas=4

# Verificar
kubectl get pods -n argocd -l app=talk-ci -o wide
Opção 3: Mudar estratégia no Git (mais rigoroso)
Atualize o deployment no Git com whenUnsatisfiable: ScheduleAnyway e maxSkew: 0 temporariamente:

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: talk-ci-deployment
  namespace: argocd
  labels:
    app: talk-ci
spec:
  replicas: 4
  selector:
    matchLabels:
      app: talk-ci
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0        # Importante: não criar pods extras
      maxUnavailable: 1  # Deletar 1 por vez
  template:
    metadata:
      labels:
        app: talk-ci
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: talk-ci
        # Adicione isto para considerar todos os pods
        minDomains: 2  # Força uso dos 2 nós
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:  # Mudou para REQUIRED
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - talk-ci
            topologyKey: kubernetes.io/hostname
            # Limitar pods por nó
            namespaceSelector: {}
      containers:
      - name: talk-ci
        image: desdiogo/2talk-ci
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: talk-ci-service
spec:
  type: NodePort
  selector:
    app: talk-ci
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080
